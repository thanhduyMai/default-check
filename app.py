
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso # Th√™m m√¥ h√¨nh h·ªìi quy
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor # Th√™m m√¥ h√¨nh h·ªìi quy
from xgboost import XGBClassifier, XGBRegressor # Th√™m m√¥ h√¨nh h·ªìi quy
from sklearn.metrics import classification_report, ConfusionMatrixDisplay, mean_squared_error, mean_absolute_error, r2_score # Th√™m metric h·ªìi quy
from scipy.stats import skew
from imblearn.over_sampling import SMOTE
# C√≥ th·ªÉ c·∫ßn th√™m: pip install imbalanced-learn

# --- Helper Function for Outlier Detection ---
def detect_outliers_iqr(series, threshold=0.1):
    """Ph√°t hi·ªán t·ª∑ l·ªá ngo·∫°i l·ªá b·∫±ng ph∆∞∆°ng ph√°p IQR."""
    if not pd.api.types.is_numeric_dtype(series):
        return 0, False # Kh√¥ng ph·∫£i s·ªë th√¨ kh√¥ng c√≥ ngo·∫°i l·ªá
    series = series.dropna()
    if series.empty:
        return 0, False
    Q1 = series.quantile(0.25)
    Q3 = series.quantile(0.75)
    IQR = Q3 - Q1
    if IQR == 0: # Tr√°nh tr∆∞·ªùng h·ª£p t·∫•t c·∫£ gi√° tr·ªã gi·ªëng nhau
        return 0, False
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = series[(series < lower_bound) | (series > upper_bound)]
    outlier_ratio = len(outliers) / len(series) if len(series) > 0 else 0
    has_significant_outliers = outlier_ratio >= threshold
    return outlier_ratio, has_significant_outliers

# --- Streamlit App ---
st.set_page_config(layout="wide")
st.title("üìä ·ª®ng d·ª•ng ph√¢n t√≠ch d·ªØ li·ªáu & hu·∫•n luy·ªán m√¥ h√¨nh")

# Upload CSV file
uploaded_file = st.file_uploader("T·∫£i l√™n file CSV d·ªØ li·ªáu c·ªßa b·∫°n", type=["csv"])

if uploaded_file is not None:
    @st.cache_data
    def load_data(file):
        try:
            return pd.read_csv(file)
        except Exception as e:
            st.error(f"L·ªói khi ƒë·ªçc file CSV: {e}")
            return None
    df = load_data(uploaded_file)

    if df is not None: # Ch·ªâ ti·∫øp t·ª•c n·∫øu load data th√†nh c√¥ng
        st.subheader("üîç Th√¥ng tin t·ªïng quan v·ªÅ d·ªØ li·ªáu")
        st.dataframe(df.head())
        st.write("K√≠ch th∆∞·ªõc d·ªØ li·ªáu:", df.shape)
        st.write("C√°c ki·ªÉu d·ªØ li·ªáu:")
        st.dataframe(df.dtypes.astype(str))

        st.subheader("üìâ Ph√¢n t√≠ch Missing Values")
        missing_percent = df.isnull().mean() * 100
        missing_percent_filtered = missing_percent[missing_percent > 0].sort_values(ascending=False)

        if not missing_percent_filtered.empty:
            fig, ax = plt.subplots(figsize=(10, 4))
            sns.barplot(x=missing_percent_filtered.index, y=missing_percent_filtered.values, ax=ax)
            ax.set_ylabel("T·ª∑ l·ªá thi·∫øu d·ªØ li·ªáu (%)")
            ax.set_xticklabels(ax.get_xticklabels(), rotation=90)
            plt.tight_layout()
            st.pyplot(fig)
        else:
            st.success("‚úÖ D·ªØ li·ªáu kh√¥ng c√≥ gi√° tr·ªã thi·∫øu!")

        with st.expander("üìä Xem bi·ªÉu ƒë·ªì ph√¢n ph·ªëi (Categorical & Numerical)"):
            st.subheader("Bi·ªÉu ƒë·ªì t·ª∑ l·ªá gi√° tr·ªã theo t·ª´ng c·ªôt (Categorical)")
            cat_cols = df.select_dtypes(include=['object', 'category']).columns
            if len(cat_cols) > 0:
                for col in cat_cols:
                    try:
                        fig, ax = plt.subplots()
                        value_counts = df[col].value_counts(normalize=True)
                        limit = 30 # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng thanh
                        if len(value_counts) > limit:
                            value_counts = value_counts.head(limit)
                            st.caption(f"C·ªôt '{col}': Ch·ªâ hi·ªÉn th·ªã {limit} gi√° tr·ªã ph·ªï bi·∫øn nh·∫•t.")
                        value_counts.plot(kind='bar', ax=ax)
                        ax.set_title(f"T·ª∑ l·ªá gi√° tr·ªã trong c·ªôt {col}")
                        ax.set_ylabel("T·ª∑ l·ªá")
                        plt.xticks(rotation=45, ha='right')
                        plt.tight_layout()
                        st.pyplot(fig)
                    except Exception as e:
                        st.error(f"L·ªói khi v·∫Ω bi·ªÉu ƒë·ªì cho c·ªôt '{col}': {e}")
            else:
                st.info("Kh√¥ng c√≥ c·ªôt d·∫°ng Categorical ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì.")

            st.subheader("Boxplot c√°c bi·∫øn s·ªë (Numerical)")
            num_cols_plot = df.select_dtypes(include=np.number).columns
            if len(num_cols_plot) > 0:
                for col in num_cols_plot:
                    try:
                        fig, ax = plt.subplots()
                        sns.boxplot(x=df[col], ax=ax)
                        ax.set_title(f"Boxplot c·ªßa {col}")
                        plt.tight_layout()
                        st.pyplot(fig)
                    except Exception as e:
                        st.error(f"L·ªói khi v·∫Ω boxplot cho c·ªôt '{col}': {e}")
            else:
                st.info("Kh√¥ng c√≥ c·ªôt d·∫°ng Numerical ƒë·ªÉ v·∫Ω boxplot.")

        # --- B·∫ÆT ƒê·∫¶U PH·∫¶N TH√äM L·∫†I ---
        st.markdown("---")
        st.subheader("üéØ Ch·ªçn bi·∫øn m·ª•c ti√™u v√† lo·∫°i b·ªè c·ªôt")

        # 1. Ch·ªçn bi·∫øn m·ª•c ti√™u (target)
        all_columns = df.columns.tolist()
        # ƒê·∫∑t c·ªôt cu·ªëi c√πng l√†m m·∫∑c ƒë·ªãnh n·∫øu c√≥ th·ªÉ
        default_target_index = len(all_columns) - 1 if len(all_columns) > 0 else 0
        target_col = st.selectbox(
            "Ch·ªçn bi·∫øn m·ª•c ti√™u (target):",
            options=all_columns,
            index=default_target_index,
            key="target_select"
        )

        if target_col:
            st.success(f"B·∫°n ƒë√£ ch·ªçn '{target_col}' l√†m bi·∫øn m·ª•c ti√™u.")
            # T·∫°o b·∫£n sao ƒë·ªÉ x·ª≠ l√Ω, gi·ªØ l·∫°i df g·ªëc n·∫øu c·∫ßn
            df_processed = df.copy()

            # 2. T√°ch X v√† y
            X = df_processed.drop(columns=[target_col])
            y = df_processed[target_col]
            st.write(f"K√≠ch th∆∞·ªõc X ban ƒë·∫ßu: {X.shape}")
            st.write(f"K√≠ch th∆∞·ªõc y ban ƒë·∫ßu: {y.shape}")

            # 3. Ch·ªçn c·ªôt mu·ªën lo·∫°i b·ªè kh·ªèi X
            available_cols_for_removal = X.columns.tolist()
            remove_cols = st.multiselect(
                "Ch·ªçn c√°c c·ªôt mu·ªën lo·∫°i b·ªè kh·ªèi t·∫≠p ƒë·∫∑c tr∆∞ng (X):",
                options=available_cols_for_removal,
                key="remove_cols_multiselect"
            )

            if remove_cols:
                X = X.drop(columns=remove_cols)
                st.success(f"ƒê√£ lo·∫°i b·ªè c√°c c·ªôt: {', '.join(remove_cols)}")
                st.write(f"K√≠ch th∆∞·ªõc X sau khi lo·∫°i b·ªè c·ªôt: {X.shape}")
            else:
                st.info("Kh√¥ng c√≥ c·ªôt n√†o ƒë∆∞·ª£c ch·ªçn ƒë·ªÉ lo·∫°i b·ªè.")

        else:
            st.warning("Vui l√≤ng ch·ªçn bi·∫øn m·ª•c ti√™u ƒë·ªÉ ti·∫øp t·ª•c.")
            st.stop() # D·ª´ng th·ª±c thi n·∫øu ch∆∞a ch·ªçn target

        # --- K·∫æT TH√öC PH·∫¶N TH√äM L·∫†I ---


        # --- X·ª≠ l√Ω d·ªØ li·ªáu (Ti·∫øp t·ª•c t·ª´ ƒë√¢y v·ªõi X v√† y ƒë√£ ƒë∆∞·ª£c x√°c ƒë·ªãnh) ---
        st.markdown("---")
        st.subheader("üßπ X·ª≠ l√Ω Missing Values trong X") # Ch·ªâ x·ª≠ l√Ω X ·ªü ƒë√¢y, y s·∫Ω x·ª≠ l√Ω ri√™ng n·∫øu c·∫ßn
        missing_columns_X = X.columns[X.isnull().any()].tolist()
        if missing_columns_X:
            st.write("C√°c c·ªôt trong X c√≥ gi√° tr·ªã thi·∫øu:", missing_columns_X)
            for col in missing_columns_X:
                if pd.api.types.is_numeric_dtype(X[col]):
                    fill_value = X[col].median() # D√πng median an to√†n h∆°n v·ªõi outliers
                    X[col].fillna(fill_value, inplace=True)
                    # st.write(f"- C·ªôt s·ªë '{col}': ƒêi·ªÅn b·∫±ng Median ({fill_value:.2f})")
                elif pd.api.types.is_object_dtype(X[col]) or pd.api.types.is_categorical_dtype(X[col]):
                    try:
                        fill_value = X[col].mode()[0]
                        X[col].fillna(fill_value, inplace=True)
                        # st.write(f"- C·ªôt ph√¢n lo·∫°i '{col}': ƒêi·ªÅn b·∫±ng Mode ('{fill_value}')")
                    except IndexError:
                         st.warning(f"- C·ªôt ph√¢n lo·∫°i '{col}': Kh√¥ng t√¨m th·∫•y mode (c√≥ th·ªÉ c·ªôt to√†n NaN). B·ªè qua.")
                    except Exception as e:
                         st.error(f"L·ªói khi ƒëi·ªÅn mode cho c·ªôt '{col}': {e}")

                else:
                     st.warning(f"- C·ªôt '{col}' trong X c√≥ ki·ªÉu d·ªØ li·ªáu {X[col].dtype} kh√¥ng ƒë∆∞·ª£c t·ª± ƒë·ªông x·ª≠ l√Ω missing value.")

            missing_total_after_X = X.isnull().sum().sum()
            if missing_total_after_X == 0:
                st.success("‚úÖ ƒê√£ x·ª≠ l√Ω to√†n b·ªô missing values trong X.")
            else:
                st.warning(f"‚ö†Ô∏è V·∫´n c√≤n {missing_total_after_X} gi√° tr·ªã thi·∫øu trong X.")
        else:
            st.success("‚úÖ T·∫≠p d·ªØ li·ªáu X kh√¥ng c√≥ gi√° tr·ªã thi·∫øu.")

        # X·ª≠ l√Ω missing values trong y (n·∫øu c√≥ v√† n·∫øu y l√† s·ªë)
        if y is not None and y.isnull().any():
             st.subheader("üßπ X·ª≠ l√Ω Missing Values trong y (Bi·∫øn m·ª•c ti√™u)")
             if pd.api.types.is_numeric_dtype(y):
                  # ƒê·ªëi v·ªõi h·ªìi quy, ƒëi·ªÅn mean/median c√≥ th·ªÉ ch·∫•p nh·∫≠n ƒë∆∞·ª£c
                  y_fill_value = y.median()
                  y.fillna(y_fill_value, inplace=True)
                  st.write(f"ƒê√£ ƒëi·ªÅn gi√° tr·ªã thi·∫øu trong bi·∫øn m·ª•c ti√™u y b·∫±ng median ({y_fill_value:.2f}).")
             else:
                  # ƒê·ªëi v·ªõi ph√¢n lo·∫°i, th∆∞·ªùng lo·∫°i b·ªè h√†ng c√≥ y b·ªã thi·∫øu
                  original_len = len(y)
                  not_na_indices = y.notna()
                  y = y[not_na_indices]
                  X = X[not_na_indices] # Quan tr·ªçng: ph·∫£i l·ªçc c·∫£ X t∆∞∆°ng ·ª©ng
                  st.warning(f"ƒê√£ lo·∫°i b·ªè {original_len - len(y)} h√†ng do gi√° tr·ªã thi·∫øu trong bi·∫øn m·ª•c ti√™u ph√¢n lo·∫°i '{target_col}'.")
                  st.write(f"K√≠ch th∆∞·ªõc X sau khi l·ªçc y: {X.shape}")
                  st.write(f"K√≠ch th∆∞·ªõc y sau khi l·ªçc: {y.shape}")


        # Encode y n·∫øu l√† ph√¢n lo·∫°i v√† ch∆∞a ph·∫£i s·ªë / X√°c ƒë·ªãnh lo·∫°i b√†i to√°n
        le_target = None # Kh·ªüi t·∫°o le_target
        is_classification = False # X√°c ƒë·ªãnh l√† b√†i to√°n ph√¢n lo·∫°i hay h·ªìi quy
        if y is not None: # Ch·ªâ x·ª≠ l√Ω n·∫øu y t·ªìn t·∫°i
            if pd.api.types.is_numeric_dtype(y):
                 # Ki·ªÉm tra s·ªë l∆∞·ª£ng gi√° tr·ªã duy nh·∫•t ƒë·ªÉ ƒëo√°n l√† ph√¢n lo·∫°i hay h·ªìi quy
                 unique_count_y = y.nunique()
                 if unique_count_y < 2:
                      st.error(f"Bi·∫øn m·ª•c ti√™u '{target_col}' ch·ªâ c√≥ {unique_count_y} gi√° tr·ªã duy nh·∫•t. Kh√¥ng th·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh.")
                      st.stop()
                 elif unique_count_y <= 20: # Ng∆∞·ª°ng ƒë·ªÉ ƒëo√°n l√† ph√¢n lo·∫°i (c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh)
                      st.write(f"Bi·∫øn m·ª•c ti√™u '{target_col}' l√† s·ªë nh∆∞ng c√≥ √≠t gi√° tr·ªã duy nh·∫•t ({unique_count_y}). Gi·∫£ ƒë·ªãnh l√† b√†i to√°n ph√¢n lo·∫°i.")
                      is_classification = True
                      # C√≥ th·ªÉ c·∫ßn encode l·∫°i th√†nh 0, 1, 2... n·∫øu gi√° tr·ªã kh√¥ng ph·∫£i v·∫≠y
                      if not np.array_equal(np.sort(y.unique()), np.arange(unique_count_y)):
                           st.write("Ti·∫øn h√†nh Label Encoding l·∫°i cho bi·∫øn m·ª•c ti√™u s·ªë ƒë·ªÉ ƒë·∫£m b·∫£o nh√£n l√† 0, 1, 2...")
                           le_target = LabelEncoder()
                           y = le_target.fit_transform(y)
                           try:
                               # S·ª≠a l·ªói hi·ªÉn th·ªã mapping cho LabelEncoder
                               target_mapping = {str(label): int(index) for index, label in enumerate(le_target.classes_)}
                               st.json(target_mapping)
                           except Exception as e:
                               st.warning(f"Kh√¥ng th·ªÉ hi·ªÉn th·ªã mapping: {e}")
                 else:
                      st.write(f"Bi·∫øn m·ª•c ti√™u '{target_col}' l√† s·ªë v√† c√≥ nhi·ªÅu gi√° tr·ªã duy nh·∫•t ({unique_count_y}). Gi·∫£ ƒë·ªãnh l√† b√†i to√°n h·ªìi quy.")
                      is_classification = False
            else: # N·∫øu kh√¥ng ph·∫£i s·ªë, ch·∫Øc ch·∫Øn l√† ph√¢n lo·∫°i
                 st.write(f"Bi·∫øn m·ª•c ti√™u '{target_col}' kh√¥ng ph·∫£i d·∫°ng s·ªë. Ti·∫øn h√†nh Label Encoding.")
                 is_classification = True
                 le_target = LabelEncoder()
                 y = le_target.fit_transform(y)
                 st.write("Mapping c·ªßa Label Encoder cho bi·∫øn m·ª•c ti√™u:")
                 try:
                      # S·ª≠a l·ªói hi·ªÉn th·ªã mapping cho LabelEncoder
                      target_mapping = {str(label): int(index) for index, label in enumerate(le_target.classes_)}
                      st.json(target_mapping)
                 except Exception as e:
                      st.warning(f"Kh√¥ng th·ªÉ hi·ªÉn th·ªã mapping: {e}")


        st.markdown("---")
        st.subheader("üßÆ X·ª≠ l√Ω c√°c bi·∫øn ƒë·∫ßu v√†o (Features) trong X")

        # --- Scaling bi·∫øn s·ªë (Linh ho·∫°t theo t·ª´ng c·ªôt) ---
        st.markdown("#### 1. Scaling bi·∫øn s·ªë (Numerical Scaling)")
        num_cols = X.select_dtypes(include=np.number).columns.tolist()
        scaling_config = {} # L∆∞u tr·ªØ l·ª±a ch·ªçn scaling cho t·ª´ng c·ªôt

        if num_cols:
            st.write("C·∫•u h√¨nh Scaling cho t·ª´ng c·ªôt s·ªë:")
            cols_per_row = 3
            col_objs = st.columns(cols_per_row)
            col_idx = 0

            default_scaler_no_outlier = "MinMaxScaler"
            outlier_threshold = 0.05
            st.caption(f"(T·ª± ƒë·ªông ƒë·ªÅ xu·∫•t RobustScaler n·∫øu t·ª∑ l·ªá outliers >= {outlier_threshold*100}%)")

            for col_name in num_cols:
                with col_objs[col_idx % cols_per_row]:
                    outlier_ratio, has_outliers = detect_outliers_iqr(X[col_name], threshold=outlier_threshold)
                    suggested_scaler = "RobustScaler" if has_outliers else default_scaler_no_outlier

                    label = f"C·ªôt '{col_name}'"
                    label_detail = f" (Outliers: {outlier_ratio:.1%})"

                    options = ["T·ª± ƒë·ªông", "MinMaxScaler", "StandardScaler", "RobustScaler", "Kh√¥ng Scale"]
                    try:
                        suggested_index = options.index(suggested_scaler)
                    except ValueError:
                        suggested_index = 1 # M·∫∑c ƒë·ªãnh l√† MinMaxScaler n·∫øu c√≥ l·ªói

                    user_choice = st.selectbox(
                        label + label_detail,
                        options=options,
                        index=0, # Lu√¥n m·∫∑c ƒë·ªãnh l√† "T·ª± ƒë·ªông"
                        key=f"scaler_{col_name}"
                    )

                    if user_choice == "T·ª± ƒë·ªông":
                        final_method = suggested_scaler
                    else:
                        final_method = user_choice

                    scaling_config[col_name] = final_method
                    st.caption(f"ƒê·ªÅ xu·∫•t: {suggested_scaler} -> Ch·ªçn: {final_method}")
                    st.markdown("---") # NgƒÉn c√°ch gi·ªØa c√°c c·ªôt

                col_idx += 1

            # √Åp d·ª•ng scaling d·ª±a tr√™n config
            st.write("üîÑ **√Åp d·ª•ng Scaling:**")
            scaled_cols_count = 0
            for col_name, method in scaling_config.items():
                if method != "Kh√¥ng Scale":
                    try:
                        if method == "MinMaxScaler":
                            scaler = MinMaxScaler()
                        elif method == "StandardScaler":
                            scaler = StandardScaler()
                        elif method == "RobustScaler":
                            scaler = RobustScaler()

                        X[[col_name]] = scaler.fit_transform(X[[col_name]])
                        # st.write(f"- C·ªôt '{col_name}': √Åp d·ª•ng {method}") # Gi·∫£m b·ªõt output
                        scaled_cols_count += 1
                    except Exception as e:
                        st.error(f"L·ªói khi scale c·ªôt '{col_name}' b·∫±ng {method}: {e}")
                # else:
                     # st.write(f"- C·ªôt '{col_name}': B·ªè qua Scaling") # Gi·∫£m b·ªõt output

            if scaled_cols_count > 0:
                 st.success(f"‚úÖ ƒê√£ √°p d·ª•ng scaling cho {scaled_cols_count}/{len(num_cols)} c·ªôt s·ªë.")
            else:
                 st.info("‚ÑπÔ∏è Kh√¥ng c√≥ c·ªôt s·ªë n√†o ƒë∆∞·ª£c scale.")

        else:
            st.write("Kh√¥ng c√≥ c·ªôt s·ªë ƒë·ªÉ scale.")

        # --- Encoding bi·∫øn ph√¢n lo·∫°i ---
        st.markdown("#### 2. M√£ h√≥a bi·∫øn ph√¢n lo·∫°i (Categorical Encoding)")
        categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()
       

        if categorical_cols:
            st.write("C√°c c·ªôt ph√¢n lo·∫°i ƒë∆∞·ª£c ph√°t hi·ªán:", categorical_cols)
            encoding_method = st.radio(
                "Ch·ªçn ph∆∞∆°ng ph√°p m√£ h√≥a cho t·∫•t c·∫£ c√°c c·ªôt tr√™n:",
                ("One-Hot Encoding", "Label Encoding (C·∫©n th·∫≠n!)"),
                index=0,
                key="encoding_method"
            )

            if encoding_method == "One-Hot Encoding":
                try:
                    original_cols = X.shape[1]
                    X = pd.get_dummies(X, columns=categorical_cols, drop_first=True, dummy_na=False)
                    new_cols = X.shape[1]
                    st.success(f"‚úÖ ƒê√£ √°p d·ª•ng One-Hot Encoding. S·ªë c·ªôt tƒÉng t·ª´ {original_cols} l√™n {new_cols}.")
                except Exception as e:
                     st.error(f"L·ªói khi th·ª±c hi·ªán One-Hot Encoding: {e}")

            elif encoding_method == "Label Encoding (C·∫©n th·∫≠n!)":
                st.warning("‚ö†Ô∏è L∆∞u √Ω: Label Encoding ch·ªâ n√™n d√πng cho bi·∫øn c√≥ th·ª© t·ª± ho·∫∑c m√¥ h√¨nh c√¢y.")
                le = LabelEncoder()
                encoded_cols_le = []
                for col in categorical_cols:
                     try:
                        X[col] = le.fit_transform(X[col].astype(str))
                        encoded_cols_le.append(col)
                     except Exception as e:
                        st.error(f"L·ªói khi Label Encoding c·ªôt '{col}': {e}")
                if encoded_cols_le:
                    st.success(f"‚úÖ ƒê√£ √°p d·ª•ng Label Encoding cho c√°c c·ªôt: {encoded_cols_le}")

            remaining_objects = X.select_dtypes(include=['object', 'category']).columns.tolist()
            if remaining_objects:
                st.warning(f"‚ö†Ô∏è V·∫´n c√≤n {len(remaining_objects)} c·ªôt d·∫°ng object/category ch∆∞a ƒë∆∞·ª£c m√£ h√≥a: {remaining_objects}")

        else:
            st.write("Kh√¥ng c√≥ c·ªôt ph√¢n lo·∫°i ƒë·ªÉ m√£ h√≥a.")
            

        bool_cols = X.select_dtypes(include=["bool"]).columns.tolist()

        st.subheader("C√°c c·ªôt boolean sau khi encode:")
        st.write(bool_cols)

        if bool_cols:
            X[bool_cols] = X[bool_cols].astype(int)
            st.success("‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi c√°c c·ªôt boolean th√†nh int.")
        else:
            st.info("Kh√¥ng c√≥ c·ªôt boolean n√†o c·∫ßn chuy·ªÉn ƒë·ªïi.")

        st.write(f"üî¢ S·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng (features) cu·ªëi c√πng trong X: {X.shape[1]}")
        st.write("Xem tr∆∞·ªõc 5 d√≤ng d·ªØ li·ªáu X ƒë√£ x·ª≠ l√Ω:")
        st.dataframe(X.head())


        # --- Chia Train/Test ---
        st.markdown("---")
        st.subheader("üöÄ Chu·∫©n b·ªã hu·∫•n luy·ªán m√¥ h√¨nh")
        test_size = st.slider("Ch·ªçn t·ª∑ l·ªá t·∫≠p ki·ªÉm tra (Test set size):", 0.1, 0.5, 0.2, 0.05, key="test_size")
        random_state = st.number_input("Nh·∫≠p Random State:", value=42, key="random_state")

        try:
            # Stratify ch·ªâ d√πng cho ph√¢n lo·∫°i
            stratify_option = y if is_classification and y is not None else None
            X_train, X_test, y_train, y_test = train_test_split(
                X, y,
                test_size=test_size,
                random_state=random_state,
                stratify=stratify_option
            )
            st.write(f"K√≠ch th∆∞·ªõc t·∫≠p hu·∫•n luy·ªán (Train): {X_train.shape}, {y_train.shape}")
            st.write(f"K√≠ch th∆∞·ªõc t·∫≠p ki·ªÉm tra (Test): {X_test.shape}, {y_test.shape}")

            # --- T√ôY CH·ªåN SMOTE ---
            if is_classification: # Ch·ªâ hi·ªÉn th·ªã SMOTE n·∫øu l√† b√†i to√°n ph√¢n lo·∫°i
                st.markdown("#### ‚öñÔ∏è C√¢n b·∫±ng d·ªØ li·ªáu hu·∫•n luy·ªán (SMOTE - T√πy ch·ªçn)")
                apply_smote = st.checkbox("√Åp d·ª•ng SMOTE cho t·∫≠p hu·∫•n luy·ªán?", key="apply_smote")

                if apply_smote:
                    st.write("Ph√¢n ph·ªëi l·ªõp (Train) tr∆∞·ªõc SMOTE:", np.bincount(y_train))
                    smote = SMOTE(random_state=random_state)
                    try:
                        if not X_train.select_dtypes(exclude=np.number).empty:
                             st.error("L·ªói SMOTE: T·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán v·∫´n c√≤n c·ªôt kh√¥ng ph·∫£i s·ªë. Vui l√≤ng ki·ªÉm tra l·∫°i b∆∞·ªõc Encoding.")
                        else:
                            X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)
                            st.success("‚úÖ √Åp d·ª•ng SMOTE th√†nh c√¥ng!")
                            st.write("K√≠ch th∆∞·ªõc t·∫≠p hu·∫•n luy·ªán sau SMOTE:", X_train_resampled.shape, y_train_resampled.shape)
                            st.write("Ph√¢n ph·ªëi l·ªõp (Train) sau SMOTE:", np.bincount(y_train_resampled))
                            X_train = X_train_resampled
                            y_train = y_train_resampled
                    except Exception as e:
                        st.error(f"L·ªói khi √°p d·ª•ng SMOTE: {e}")
                else:
                    st.info("‚ÑπÔ∏è Kh√¥ng √°p d·ª•ng SMOTE.")
            # --- K·∫æT TH√öC PH·∫¶N SMOTE ---

            # --- Ch·ªçn v√† Hu·∫•n luy·ªán M√¥ h√¨nh ---
            st.markdown("---")
            st.subheader("ü§ñ Ch·ªçn v√† Hu·∫•n luy·ªán M√¥ h√¨nh")

            if is_classification:
                model_options = ["Logistic Regression", "Decision Tree", "Random Forest", "XGBoost"]
                st.write("Ch·ªçn m√¥ h√¨nh ph√¢n lo·∫°i:")
            else:
                # Th√™m c√°c m√¥ h√¨nh h·ªìi quy ·ªü ƒë√¢y n·∫øu mu·ªën
                model_options = ["Linear Regression", "Ridge", "Lasso", "Random Forest Regressor", "XGBoost Regressor"] # V√≠ d·ª•
                st.write("Ch·ªçn m√¥ h√¨nh h·ªìi quy:")
                # C·∫ßn import c√°c m√¥ h√¨nh h·ªìi quy t∆∞∆°ng ·ª©ng (ƒë√£ import ·ªü ƒë·∫ßu)


            model_choice = st.selectbox("Ch·ªçn m√¥ h√¨nh:", model_options, key="model_choice")

            if st.button(f"üöÄ Hu·∫•n luy·ªán m√¥ h√¨nh {model_choice}"):
                with st.spinner(f"ƒêang hu·∫•n luy·ªán {model_choice}..."):
                    model = None
                    try:
                        # --- Kh·ªüi t·∫°o m√¥ h√¨nh ---
                        if model_choice == "Logistic Regression":
                            if not is_classification: st.error("Logistic Regression ch·ªâ d√πng cho ph√¢n lo·∫°i."); st.stop()
                            model = LogisticRegression(random_state=random_state, max_iter=1000, n_jobs=-1)
                        elif model_choice == "Decision Tree":
                            if not is_classification: st.error("Decision Tree Classifier ch·ªâ d√πng cho ph√¢n lo·∫°i."); st.stop()
                            model = DecisionTreeClassifier(random_state=random_state)
                        elif model_choice == "Random Forest":
                             if is_classification:
                                 model = RandomForestClassifier(random_state=random_state, n_jobs=-1)
                             else:
                                 model = RandomForestRegressor(random_state=random_state, n_jobs=-1) # RF cho h·ªìi quy
                        elif model_choice == "XGBoost":
                             if is_classification:
                                 num_classes_final = len(np.unique(y_train))
                                 model = XGBClassifier(
                                     random_state=random_state, use_label_encoder=False,
                                     eval_metric='logloss' if num_classes_final == 2 else 'mlogloss',
                                     n_jobs=-1
                                 )
                             else:
                                 model = XGBRegressor(random_state=random_state, n_jobs=-1, objective='reg:squarederror') # XGB cho h·ªìi quy
                        # Th√™m c√°c m√¥ h√¨nh h·ªìi quy kh√°c
                        elif model_choice == "Linear Regression":
                             if is_classification: st.error("Linear Regression ch·ªâ d√πng cho h·ªìi quy."); st.stop()
                             model = LinearRegression(n_jobs=-1)
                        elif model_choice == "Ridge":
                             if is_classification: st.error("Ridge ch·ªâ d√πng cho h·ªìi quy."); st.stop()
                             model = Ridge(random_state=random_state)
                        elif model_choice == "Lasso":
                             if is_classification: st.error("Lasso ch·ªâ d√πng cho h·ªìi quy."); st.stop()
                             model = Lasso(random_state=random_state)
                        # Th√™m c√°c m√¥ h√¨nh kh√°c n·∫øu c·∫ßn...
                        else:
                             st.error("M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c h·ªó tr·ª£")
                             st.stop()

                        # --- Hu·∫•n luy·ªán ---
                        model.fit(X_train, y_train)
                        st.success(f"‚úÖ Hu·∫•n luy·ªán m√¥ h√¨nh {model_choice} ho√†n t·∫•t!")

                        # --- ƒê√°nh gi√° m√¥ h√¨nh ---
                        st.subheader("üìà K·∫øt qu·∫£ ƒë√°nh gi√° m√¥ h√¨nh (tr√™n t·∫≠p Test)")
                        y_pred = model.predict(X_test)

                        if is_classification:
                            st.text("Classification Report:")
                            report = classification_report(y_test, y_pred, zero_division=0)
                            st.text(report)

                            st.text("Confusion Matrix:")
                            try:
                                fig, ax = plt.subplots()
                                # L·∫•y nh√£n g·ªëc n·∫øu ƒë√£ encode
                                display_labels = le_target.classes_ if le_target is not None else np.unique(y_test)
                                ConfusionMatrixDisplay.from_estimator(
                                    model, X_test, y_test,
                                    ax=ax, cmap="Blues",
                                    display_labels=display_labels
                                )
                                plt.xticks(rotation=45, ha='right')
                                plt.yticks(rotation=0)
                                st.pyplot(fig)
                            except Exception as e:
                                st.error(f"L·ªói khi v·∫Ω Confusion Matrix: {e}")
                                from sklearn.metrics import confusion_matrix
                                cm = confusion_matrix(y_test, y_pred)
                                st.text("Ma tr·∫≠n nh·∫ßm l·∫´n (d·∫°ng s·ªë):")
                                st.dataframe(cm)
                        else: # ƒê√°nh gi√° h·ªìi quy
                             mse = mean_squared_error(y_test, y_pred)
                             mae = mean_absolute_error(y_test, y_pred)
                             r2 = r2_score(y_test, y_pred)
                             st.write(f"Mean Squared Error (MSE): {mse:.4f}")
                             st.write(f"Mean Absolute Error (MAE): {mae:.4f}")
                             st.write(f"R-squared (R¬≤): {r2:.4f}")

                             # Bi·ªÉu ƒë·ªì d·ª± ƒëo√°n vs th·ª±c t·∫ø
                             fig, ax = plt.subplots()
                             ax.scatter(y_test, y_pred, alpha=0.5)
                             ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r', lw=2)
                             ax.set_xlabel("Gi√° tr·ªã th·ª±c t·∫ø")
                             ax.set_ylabel("Gi√° tr·ªã d·ª± ƒëo√°n")
                             ax.set_title("Th·ª±c t·∫ø vs. D·ª± ƒëo√°n")
                             st.pyplot(fig)


                    except Exception as train_error:
                        st.error(f"L·ªói trong qu√° tr√¨nh hu·∫•n luy·ªán ho·∫∑c ƒë√°nh gi√°: {train_error}")

        except ValueError as ve:
             st.error(f"L·ªói khi chia d·ªØ li·ªáu Train/Test: {ve}")
             st.warning("Ki·ªÉm tra l·∫°i bi·∫øn m·ª•c ti√™u v√† c√°c ƒë·∫∑c tr∆∞ng. ƒê·∫£m b·∫£o X v√† y c√≥ c√πng s·ªë h√†ng.")
        except Exception as e:
             st.error(f"ƒê√£ x·∫£y ra l·ªói kh√¥ng mong mu·ªën: {e}")

else:
    st.info("üí° Vui l√≤ng t·∫£i l√™n file CSV ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
    st.warning("L∆∞u √Ω: B·∫°n c√≥ th·ªÉ c·∫ßn c√†i ƒë·∫∑t th∆∞ vi·ªán `imbalanced-learn` ƒë·ªÉ s·ª≠ d·ª•ng SMOTE: `pip install imbalanced-learn`")

